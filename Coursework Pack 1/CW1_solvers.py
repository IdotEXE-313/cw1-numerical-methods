"""
Main Python script for submission
Implements the required functions for CW1.
"""
from typing import Callable
import numpy as np
import matplotlib.pyplot as plt

def show_answer(func, word_limit=40):
    """
    Do not remove or modify this function
    """
    
    text = func.__doc__ or ""
    words = text.split()

    limited = words[:word_limit]
    truncated = len(words) > word_limit

    result = " ".join(limited)
    if truncated:
        result += " ...[truncated]"

    return result


def fixedpoint_with_stopping(g:Callable[[float],float], p0:float, Nmax:int, TOL:float, p:float=None, C:float=None, k:float=None):
    """
    
    Using the fixed-point iteration method, this function solves the problem p = g(p)

    Inputs:
    ----------

    g: Callable[[float],float]
        The function which will be iterated over
    p0: float
        The initial guess to the solution of p = g(p)
    Nmax: integer
        The maximum number of iterations over g
    TOL: float
        The tolerance for the stopping criteria defined as |p_m - p_(m-1)| <= TOL
    p: float
        The exact solution to p = g(p) if known, otherwise it is None
    C: float
        One of the positive constants used to define the stopping criteria |p - p_n| <= CK^n 
    k: float
        One of the positive constants used to define the stopping criteria |p - p_n| <= CK^n

    Output:
    ----------
    p_array: np.ndarray
        Containing the iterates p_n generated by the fixed point iteration before or after reaching Nmax iterations
    fig,ax: matplotlib.pyplot objects of the graph of the absolute errors of |p-p_n| if p is provided. 
            Also outputs the plot of the error bound Ck^n if C and k are provided
            Defaults to None if none of p, C or k are provided
    
    """


    p_array = np.zeros(Nmax)

    #Compute and store first iterate separately to initiate our iterations
    p0 = g(p0)
    p_array[0] = p0 

    n = 1
    while n < Nmax:
        p_n = g(p0)
        p_array[n] = p_n
        #Checks whether the approximation for p is converging
        if(np.abs(p_n - p_array[n-1]) <= TOL):
            break
        p0 = p_n
        n += 1
    p_array = p_array[:n+1] #Only return the non-zero part of the initialised array


    if p is not None:
        fig, ax = plt.subplots()
        errors = np.abs(p - np.array(p_array))
        n = np.arange(len(errors))

        ax.set_yscale("log")
        ax.set_xlabel("Iteration")
        ax.set_ylabel("|p - p_n|")

        ax.plot(n, errors, label="|p - p_n|")

        if C is not None and k is not None:
            bound = C * (k ** n)
            ax.plot(n, bound, "--", label="Ck^n")
        ax.legend()
    else:
        fig = ax = None

    if fig is not None and ax is not None:
        return p_array, fig, ax
    else:
        return p_array

def q1B_answer():
    """
    Answer to Question 1b(i): Linear
    
    Answer to Question 1b(ii): It is required that g'(p) = 0 for an order of convergence that is at least quadratic. For the p calculated in part a, g'(p) =/= 0 and therefore cnanot have any order of convergence that isn't linear.
        
    """
    pass

def q1C_answer():
    """
    Answer to Question 1c(i): No

    Answer to Question 1c(ii): Since p -> 0, then |g'(p)| = 0, but 0 < k < 1. Hence Theorem 1.6 is not invoked since we require 0 < k < 1 to exist such that |g(p)|<=k
        
    """
    pass

#bisection_simple method taken from listing 1.2 of the lecture notes
def bisection_simple(f,a,b,Nmax):
    """
    Bisection Method: Returns a numpy array of the 
    sequence of approximations obtained by the bisection method.
    
    Inputs:
    ----------
    f : function
        Input function for which the zero is to be found.
    a : float
        Left side of interval.
    b : float
        Right side of interval.
    Nmax : integer
        Number of iterations to be performed.

    Returns
    -------
    p_array : numpy.ndarray, 
            Array containing the sequence of approximations. 
            The shape is (Nmax,)
    """
    
    #Initialise numpy array of size Nmax
    p_array=np.zeros(Nmax,)
    
    #Begin bisection method:
    fa=f(a)
    for n in range(Nmax):
        p=(a+b)/2  # midpoint
        fp=f(p)    # evaluate f at midpoint
        #define new interval
        if fp*fa>0:
            a=p
            fa=fp
        else:
            b=p
        p_array[n]=p
    return p_array

def newton_with_stopping(f:Callable[[float],float],df:Callable[[float],float], p0:float,Nmax:int,TOL:float,p:float=None):
    """
    Implementation of the Newton method for fixed points and root finding of a function 'f'

    Inputs:
    ----------

    Inputs: 
        f: Callable[[float],float]
            The function 'f' for which we aim to find the root of.
        df: Callable[[float],float]
            The derivative of the function 'f'
        p0: float
            The initial guess of the root of 'f' to start the Newton method
        Nmax: integer
            The maximum number of iterations of the Newton method
        TOL: float
            Tolerance for the stopping criteria |f(p_m)| <= TOL
        p: float
            The exact root. Defaults to None if not provided

    Output:
    ----------
        p_array: numpy.ndarray
            The iterations of p_n generated by Newton's methpd
        fig,ax: matplotlib.pyplot objects of the absolute error |p-p_n|. None if p is not provded.

    """
   
    
    p_array=np.zeros(Nmax,)

    n = 0
    while n < Nmax:
        p_n = p0 - (f(p0) / df(p0)) #General formula for Newton's method
        p_array[n] = p_n
        if(np.abs(f(p_n)) <= TOL): #Checks for convergence based on our choice of TOL
            break
        n += 1
        p0 = p_n
    p_array = p_array[:n+1] #Ensures that only the non-zero part of the array is returned

    
    fig = ax = None

    if(p is not None):
        fig, ax = plt.subplots()
        errors = np.abs(p - np.array(p_array))

        ax.set_yscale("log")
        ax.set_xlabel("'nth' iteration")
        ax.set_ylabel("|p-p_n|")

        ax.plot(np.arange(len(errors)), errors, label="|p-p_n|")

        ax.legend()


    if fig is not None and ax is not None:
        return p_array, fig, ax
    else:
        return p_array


def q2B_answer():
    """
    Answer to Question 2b(i): Yes

    Answer to Question 2b(ii): At p=1, f(1) = 0 and f'(1) = 0. Corollary 1.2 requires that f'(p) is not equal to 0 for quadratic convergence, so the corollary doesn't apply here.
    """
    pass

def secant_with_stopping(f:Callable[[float],float], p0:float, p1:float, Nmax:int, TOL:float):
    """
    Implements the secant method to find a root of the function 'f'

    Inputs:
    ----------
    f: Callable[[float],float]
        The function for which we aim to find the root
    p0: float
        One of the initial approximations to start the Secant method
    p1: float
        One of the initial approximations to start the Secant method
    Nmax: integer
        The maximum number of iterations of the Secant method
    TOL: float
        Tolerance for the stopping criteria |p_m - p_(m-1)| <= TOL(1 + |p_m|)

    Outputs:
    ----------
    p_array: numpy.ndarray
        The iterations of p_n generated by the Secant method

    """

    p_array=np.zeros(Nmax,)

    p_array[0] = p1

    n = 1

    #Evaluates function at initial guesses of p
    q0 = f(p0)
    q1 = f(p1)
    while n < Nmax:
        denom_correction = 1e-15 if np.abs(q1 - q0) < 1e-15 else q1 - q0 #Maintain precision to avoid a zero division error when q1-q0 is sufficiently small

        p = p1 - (q1 * ((p1-p0)/(denom_correction)))

        if(np.abs(p - p_array[n-1]) <= TOL*(1 + np.abs(p))): #Check for convergence based on our choice of TOL
            break
        p_array[n] = p
        n += 1

        #Shifts iterates before performing the Secant method again
        p0 = p1
        q0 = q1
        p1 = p
        q1 = f(p)
    
    return p_array[:n] #Ensures that we only return the non-zero part of the array



def plot_convergence(p, f, df,  p0_newton, p0_sec, p1_sec,Nmax, TOL):
    """
    Currently this function plots the error |p-p_n| obtained via Newton's and
    Secant methods encoded in the functions above (once completed). 
    You must modify this modify this function to include bisection method 
    following the instructions. 
    
    
    Inputs:
    ----------
    p: float
        Eact root    
    f : function
        Input function for which the zero is to be found.
    df : function
        Derivative of the input function for which the zero is to be found.
    p0_newton : float
        initial approximation for Newton's method'
    p0_sec : float
        initial approximation for secant method
    p1_sec : float
        initial approximation for secant method
    Nmax : integer
        Number of iterations to be performed.
    TOL : float
        Tolerance for stopping criteria

    Output:
    -------
    fig, ax: matplotlib.pyplot objects of the figure that is produced
    

    """
    methods = ["newton", "secant", "bisection"]

    # map method name -> function that returns the iterate list/array
    runners = {
        "newton": newton_with_stopping(f, df, p0_newton, Nmax, TOL),
        "secant": secant_with_stopping(f, p0_sec, p1_sec, Nmax, TOL),
        "bisection": bisection_simple(f, min(p0_sec,p1_sec), max(p0_sec, p1_sec),Nmax)
    }
    #define plotting style
    styles = {
        "newton": dict(marker="*", linestyle="--", color="blue",  label="Newton"),
        "secant": dict(marker="o", linestyle="-",  color="black", label="Secant"),
        "bisection": dict(marker="*", linestyle="-", color="green", label="Bisection")
    }



    fig, ax = plt.subplots()
    ax.set_yscale("log")
    ax.set_xlabel("iteration ($n$)", fontsize=16)
    ax.set_ylabel(r"$|p - p_{n}|$", fontsize=16)
    ax.grid(True)
    
    #loop over methods and plot errors
    
    for m in methods:
        iters =runners[m]
        n = np.arange(1, len(iters) + 1)
        ax.plot(n, np.abs(iters - p), **styles[m])

    ax.legend(fontsize=16, loc="best")
    
    return fig, ax
    

def q4B_answer():
    """
    Answer to Question 4b(i): Yes. f is continuous over the interval [-2,-1] and f(a)f(b) = -6 < 0. By theorem 1.1, we are guaranteed to have convergence
        
    
    Answer to Question 4b(ii): No. Newton's method is only guaranteed to converge if p0 lies in the interval [p-delta, p+delta] for some delta > 0. 
        
    
    Answer to Question 4b(iii): Yes, Newton's method and the secant method fails to converge because |p-p_n| does not decrease towards 0, and instead oscillates above 0
    
    """
    pass


def scaled_pivoting(A:np.ndarray, b:np.ndarray ,m:int):
    """
    Implements Gaussian elimination with scaled partial pivoting to solve the system of equations Ax=b

    Inputs:
    ---------
    A: numpy.ndarray
        Represents the square matrix 'A' with shape (n,n)
    b: numpy.ndarray
        Represents the column vector 'b' with shape (n,1)
    m: integer
        Used to prematurely stop the Gaussian elimination where 1<= m <= n-1
    
    Outputs:
    ----------
    tildeA: numpy.ndarray
        Augmented matrix arrived at by starting with tildeA = [A | b] and performing Gaussian elimination with scaled partial pivoting.
    perm: numpy.ndarray
        Permutation vector that records the row ordering of the original augmented matrix [A | b]
    
    """

    #Creates the augmented matrix [A | b]
    tildeA = np.hstack((A,b))
    n = np.shape(tildeA)[0]

    perm = np.arange(n)
    scaling_factors = np.zeros(n,)
    
    #Compute scaling factors used later in the algorithm.
    for i in range(0, n):
        s_i = np.max(np.abs(tildeA[i,:n]))
        if(s_i) == 0:
            raise ValueError("There is no unique solution for this system of equations")
        scaling_factors[i] = s_i
        
    #Performs elimination for the first 'm' pivot columns
    for i in range(0, m):
        col = np.abs(tildeA[i:n,i])
        ratio = col / scaling_factors[i:]
        p = np.argmax(ratio) + i #ensures that for i>0, we get the correct row (e.g. for i=1, if p=1, then without adding i, we could be referring to row 2 when we need row 3 for a 3x3 matrix)

        #Swap rows p and i
        if p != i:
            tildeA[[p,i]] = tildeA[[i,p]]
            scaling_factors[[p,i]] = scaling_factors[[i,p]]
            perm[[p,i]] = perm[[i,p]]
        
        #This section is taken from listing 2.7 (eliminates entries below the pivot)
        for j in range(i+1,n):
            mult = tildeA[j,i] / tildeA[i,i]
            tildeA[j,i] = 0
            tildeA[j, i+1:] -= mult * tildeA[i, i+1:]

    return tildeA, perm

def backward_substitution(tildeA):
    """
    Returns an array representing the solution x of Ax=b computed using
    backward substitution after the augmented matrix tildeA has been sucesfully computed 
    via Gaussian elimination. 
    
    Parameters
    ----------
    tildeA : numpy.ndarray of shape (n,n+1)
        Array representing the augmented matrix [U v].
    n : int
        Integer that is at least 2.
        
    Returns
    -------
    x : numpy.ndarray of shape (n,1)
        Array representing the solution x.
    """
    n = np.shape(tildeA)[0]
    x=np.zeros([n,1])
    
    #check for a_{n,n} =0 
    if tildeA[n-1, n-1] == 0:        
      raise ValueError("The system does not have unique solution.")        

    #start back substitution
    x[n-1] = tildeA[n-1,n] / tildeA[n-1,n-1]
    
    for i in np.arange(n-1,0,-1):
        #Computing the sum 
        s = 0
        for j in np.arange(i+1,n+1):
            s = s + tildeA[i-1,j-1]*x[j-1]
        x[i-1] = (tildeA[i-1,n] - s) / tildeA[i-1,i-1]
    
    return x

def sp_solve(A:np.ndarray,b:np.ndarray):
    """
    Fully solves the linear system Ax=b using scaled partial pivoting and returns the solution of 'x'

    Inputs:
    ---------
    A: numpy.ndarray
        Represents the square matrix 'A' with shape (n,n)
    b: numpy.ndarray
        Represents the column vector 'b' with shape (n,1)

    Outputs:
    ----------
    x: numpy.ndarray
        The solution to the linear system Ax=b of shape (n,1)
    
    """

    n = np.shape(A)[0]
    tildeA, _ = scaled_pivoting(A,b,n-1) #we select m = n-1 since we want to perform Gaussian elimination on every column of A
    x = backward_substitution(tildeA)

    return x

            


def q5C_answer():
    """
    Answer to Question 5ci: x = [-1,1,1]
    
    Answer to Question 5cii: We observe catastrophic cancellation between 1 and 1+epsilon; since we lose precision for epsilon this small, the difference is indistinguishable from 0. This is an issue when dividing by the pivot which is essentially the same as dividing by 0.
        
    """
    pass
